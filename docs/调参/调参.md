# 数学分析和ML调参

对于zenfs运用数学分析和ML进行调参。

## 初步设想

当前的测试是db_bench。由于zenfs作为rocksdb的插件一起编译，所以一次编译时间很长。

因此我们的设想是编译一次，测试多次，利用调整的参数进行测试。

进行动态调参，每一次运行db_bench的脚本进行训练，以吞吐量作为target。

## 可调参数调研

### 连续值

对于连续值，利用db_bench使用的gflags定义参数，传入进行更改。

* zenfs中的GC_START_LEVEL，目前系统设定是默认当free空间比率小于20%时进行垃圾回收

* zenfs中的GC_SLOPE，目前系统通过thread=(100 - GC_SLOPE * (GC_START_LEVEL - free_percent))设定，如果一个块的垃圾百分数也即garbage_percent_approx = 100 - 100 * zone.used_capacity / zone.max_capacity大于thread则回收这个zone
* ZBD中的finish_threshold_，当一块zone中的剩余容量小于预定义的阈值时该块就会被finish
* 原gc是睡眠一段时间就直接gc，可以改进睡眠时间或者根据系统吞吐量进行gc

### 离散值

对于离散值，todo

* ZBD抽象的方式，比如将每个zone抽象成文件的方式，或者直接抽象成内存数组的方式，绕开了posix文件系统调用
* 调整raid级别类型，预设可以调整raid0，raid1，raid5，调整raid

## 基于方差的方法判定参数重要性

参考论文：Carver: Finding Important Parameters for Storage System Tuning

由于参数越多，调整参数的维度会越大，因此第一步就是对参数进行降维处理，而降维可以分为特征提取和特征选择两大类。

首先，我们认为基于特征提取的方法是不合适的，特征提取是指将高维数据投影到低维空间；新构建的特征通常是原始特征的线性或非线性组合。常见的特征提取方法包括主成分分析 (PCA) 、独立成分分析和线性判别分析。特征提取的一个主要缺点是每个特征的物理意义都会因投影和许多维度的非线性组合而丢失。因此，为了保留原始的物理意义，我们没有采用基于特征提取的降维方法。

基于特征选择的降维方案是我们所选择的，特征选择直接从原始特征中选择一个特征子集，目的是只找到重要的特征。特征选择方法可以分为监督或非监督。无监督特征选择，例如 Principle Feature Analysis，根据特征之间的关系选择包含大部分基本信息的子集。在选择阶段不考虑特征对优化目标的影响。相反，有监督的特征选择选择一个可以区分或近似目标变量的子集。示例包括基于决策树的算法 。由于我们有兴趣找到对我们的优化目标有重大影响的参数，例如 I/O 吞吐量，因此有监督的特征选择最适合我们的需求。

在有监督的特征选择降维方案中，考虑到参数中存在离散值，如果用诸如lasso回归的数学分析方法，不仅难于处理离散值，而且计算量较大，因此，我们采用基于方差的数学方法来选择最重要的参数类别。

具体流程如下所示：

### 1. 首先根据PI系数计算出最重要的参数，PI系数根据方差给出定义：

$$
Var(S)=\frac{1}{|S|} \sum_{i=1}^{|S|}(y_i-μ)^2
$$

$$
PI(P)=Var(S)-\sum_{i=1}^N\frac{S_{P=P_i}}{S}Var(S_{P=p_i})
$$

这里PI系数越大，由于Var(S)是个常数，PI系数的后一项是当参数中的P取不同值时将S拆分成子集，获得这些子集的方差加权而成，如果后半部分越小，说明P这个参数的影响力越大，也就是说当PI系数大时，参数P是重要的参数。因此第一步选出这里最大的作为最重要的调参参数。

### 2. 再用固定之前选定参数的方式选择最重要参数，给出了条件参数重要性的公式如下所示：

$$
CPI(Q|P=p)=Var(S_{P=p})-\sum_{j=1}^m\frac{|S_{Q=w_j,P=p|}}{S_P=p}Var(S_{Q=q_j|P=p})
$$

对于所有P中的取值，选择其中最大的作为CPI指数：
$$
CPI(Q|P)=\mathop{\max}_{i=1}^nCPI(Q|p=p_i)
$$
选择下一个最大值的参数作为次重要参数。

### 3. 停止条件

停止的方案有两种：

* 当选择的参数到了一定个数

* CPI指数已经降低到一定阈值以下，说明剩余的参数对于目标而言影响不大

## 调参方案

### 基于高斯过程回归的调参方案

#### 对ottertune调参系统的调研

通过对https://dl.acm.org/doi/10.1145/3035918.3064029论文的调研，构建了基于高斯过程回归的调参方案。在原来的论文中ottertune系统首先是对数据库的原来训练中数据的表征负载用因子分析方法进行降维，之后将当前工作负载在降维的空间内进行聚类，将当前的负载映射到相似的负载类中，再用lasso回归选择出重要的参数进行调整。在我们的调参系统中，重要参数的选择已经由基于方差的方法选择出。

接下来，ottertune利用高斯过程回归对参数进行调整，高斯过程回归是一种和深度神经网络威力相当的调参技术，其中ottertune有两种调整策略：

* 探索未知区域的参数并预测调整参数的效果
* 探索最优参数附近参数的效果

这里我们采用了第二种方案，即在最优参数附近寻找参数，预测调整目标结果，以期望达到更好的效果。

#### 高斯过程回归的原理

在概率论和统计学中，高斯过程(Gaussian process, GP)是观测值出现在一个连续域(例如时间和空间)的随机过程。在高斯过程中，连续输入空间中每一点都是与一个正态分布的随机变量相关联。此外，这些随机变量的每个有限集合都有一个多维正态分布，换句话说他们的任意有限线性组合是一个正态分布。高斯过程的分布是所有(无限多个)随机变量的联合分布，正因如此，它是连续域(例如时间和空间)上的函数分布。

从上到下其实是一个从一维到多维到无限维拓展的过程，如果我们把函数理解成在连续域上的无限维变量的话。一维变量服从一维高斯分布，多维变量服从多维高斯分布，函数服从高斯过程。或者说，高斯过程是函数的一种概率分布。

因此，在我们的问题中，就是利用已经存在的训练参数，对函数的分布进行概率上的预测回归，利用拟合的函数，探索最优参数附近参数的效果。





